{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnBortotti/Bayes-Sklearn-test/blob/main/Bayes_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcL-ZifssDKw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, top_k_accuracy_score, classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import spacy\n",
        "\n",
        "import string\n",
        "import math\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x6ByMYAss7c"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "pt_stopwords = stopwords.words('portuguese')\n",
        "\n",
        "os.system(\"python -m spacy download pt_core_news_lg\")\n",
        "\n",
        "spacy_nlp_model = spacy.load('pt_core_news_lg', disable=[\n",
        "    \"tagger\", \"parser\", \"ner\", \"textcat\", \"entity_linker\", \n",
        "    \"attribute_ruler\", \"entity_ruler\", \"morphologizer\",\n",
        "    \"senter\", \"tok2vec\", \"transformer\"\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ToZzIH2szhF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oHgLww2t5qA"
      },
      "outputs": [],
      "source": [
        "# set csv path and separator\n",
        "csv = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kaggle_databases/tweet_emotions.csv', sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLLR-ur8v-9N"
      },
      "outputs": [],
      "source": [
        "# csv config labels, columns, etc...\n",
        "csv_comment_column = 'content'\n",
        "csv_label_column = 'sentiment'\n",
        "csv = csv[[csv_comment_column, csv_label_column]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9KhEWzSwMwH"
      },
      "outputs": [],
      "source": [
        "# text processing (remove stopwords, tokenization)\n",
        "train_dataset = []\n",
        "\n",
        "bad_words = set(pt_stopwords + list(string.punctuation))\n",
        "\n",
        "for i, row in csv.iterrows():\n",
        "  treated_string = \"\"\n",
        "  row_tokens = row_tokens = spacy_nlp_model(row[csv_comment_column].lower())\n",
        "  for token in row_tokens:\n",
        "    word = token.lemma_\n",
        "    if not (word in bad_words):\n",
        "        treated_string += word\n",
        "  if treated_string != \"\":\n",
        "    train_dataset.append((treated_string, row[csv_label_column]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywZaYGwSxYP7"
      },
      "outputs": [],
      "source": [
        "# shuffle dataset\n",
        "train_dataframe = pd.DataFrame(train_dataset)\n",
        "train_dataframe = train_dataframe.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# droping some rows to avoid RAM crashing on Google Colab\n",
        "train_dataframe = train_dataframe[:20000]"
      ],
      "metadata": {
        "id": "bQuMtWTPzC77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_na4L68xdrf"
      },
      "outputs": [],
      "source": [
        "# slice dataframe (train and validation)\n",
        "total_len = len(train_dataframe)\n",
        "train_len = math.floor(len(train_dataframe)*7/10)\n",
        "\n",
        "validation_dataframe = train_dataframe[train_len+1:]\n",
        "train_dataframe = train_dataframe[0:train_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyUiGa19xopP"
      },
      "outputs": [],
      "source": [
        "# labels encoding\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "train_labels=label_encoder.fit_transform(train_dataframe[1])\n",
        "\n",
        "# input encoding\n",
        "vectorizer = CountVectorizer()\n",
        "train_inputs = vectorizer.fit_transform(train_dataframe[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKHIGeC3xyct"
      },
      "outputs": [],
      "source": [
        "# training step\n",
        "model = MultinomialNB()\n",
        "model.fit(train_inputs.toarray(), train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhWf-VUHx17t"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "validation_encoded = vectorizer.transform(validation_dataframe[0]).toarray()\n",
        "validation_predict = model.predict(validation_encoded)\n",
        "\n",
        "print('Accuracy:', accuracy_score(label_encoder.transform(validation_dataframe[1]), validation_predict))\n",
        "print('Test dataset:', len(train_inputs.toarray()))\n",
        "print('Validation dataset:', len(validation_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# report\n",
        "print(classification_report(label_encoder.transform(validation_dataframe[1]), validation_predict, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "id": "XuJJI5VOz0MH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1V2K-7BcqVC6xr3hBGDJmzXvD_FVsW4xg",
      "authorship_tag": "ABX9TyObbvBWeEf2xXFHHyK5B41M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}